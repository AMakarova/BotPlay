{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMakarova/BotPlay/blob/main/Bot_Play_FM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSCHHBL--hCB"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd 'drive/MyDrive/The Movie Dataset'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFV3cFsTiuhq",
        "outputId": "bb2324d5-7d77-4392-b0dd-82631b759cb3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/The Movie Dataset'\n",
            "/content/drive/MyDrive/The Movie Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JxsZI_y97Zu"
      },
      "source": [
        "# Build Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgu50Xc2Y9ZF"
      },
      "source": [
        "## Process ratings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from typing import Optional\n",
        "import random\n",
        "import os.path\n",
        "import ast"
      ],
      "metadata": {
        "id": "z5kGzCJtnrJA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RATINGS_PATH = \"ratings.csv\"\n",
        "RECODED_RATINGS_PATH = 'ratings_recoded.csv'\n",
        "METADATA_PATH = \"movies_metadata.csv\"\n",
        "LINKS_PATH = \"links.csv\"\n",
        "\n",
        "TOP_MOVIE_COUNT = 100\n",
        "MIN_RATINGS = 10"
      ],
      "metadata": {
        "id": "mx7oxF9MohoN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(\n",
        "    path: str = RATINGS_PATH,\n",
        "    cols: Optional[list] = None,\n",
        "    ):\n",
        "  '''\n",
        "  Loads dataset as DataFrame, filters to specified list of columns\n",
        "  '''\n",
        "  print(f\"Loading {path} dataset...\")\n",
        "  dataset = pd.read_csv(path, low_memory=False)\n",
        "  if cols:\n",
        "    return dataset[cols]\n",
        "  else:\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Nj8hAsuAnrGK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_frequencies(ratings: pd.DataFrame):\n",
        "  '''\n",
        "  Prints user and movie count\n",
        "  '''\n",
        "  users = ratings['userId'].unique().size\n",
        "  movies = ratings['movieId'].unique().size\n",
        "  print(f\"Dataset contains {users} unique users and {movies} unique movies\")"
      ],
      "metadata": {
        "id": "SYeRiNPbo4zi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subset_ratings(\n",
        "    ratings: pd.DataFrame, \n",
        "    top_movie_count: int = TOP_MOVIE_COUNT, \n",
        "    min_ratings: int = MIN_RATINGS\n",
        "    ) -> pd.DataFrame:\n",
        "  '''\n",
        "  Subsets ratings dataset\n",
        "  '''\n",
        "  print(f\"Subsetting ratings dataset...\")\n",
        "  movie_frequencies = ratings.groupby('movieId').count().sort_values('rating', ascending=False)\n",
        "  ratings = ratings[ratings['movieId'].isin(movie_frequencies.index[:top_movie_count])]\n",
        "                                            \n",
        "  user_frequencies = ratings[ratings['rating']>=4].groupby('userId').count()['rating']\n",
        "  ratings = ratings[ratings['userId'].isin(user_frequencies[user_frequencies>=min_ratings].index)]\n",
        "  print_frequencies(ratings)\n",
        "  return ratings"
      ],
      "metadata": {
        "id": "sA-tTxeFp7pl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binarise_dataset(ratings: pd.DataFrame) -> pd.DataFrame:\n",
        "  '''\n",
        "  Modify the dataset by:\n",
        "  * recoding movies with rating >=4 as positive class\n",
        "  * recoding movies with rating <4 as negative class\n",
        "  * sampling additional movies for the negative class from the set of unrated movies\n",
        "  '''\n",
        "  print(f\"Binarising ratings dataset and balancing classes.\")\n",
        "  recoded_ratings = pd.DataFrame()\n",
        "\n",
        "  for u in tqdm(ratings['userId'].unique()[:50000]): # free runtime seems to disconnect after this point\n",
        "    user_subset = ratings[ratings['userId']==u]\n",
        "    positive_class = user_subset[user_subset['rating']>=4]\n",
        "    positive_class.loc[:, 'rating'] = 1\n",
        "    negative_class = user_subset[user_subset['rating']<4]\n",
        "    negative_class.loc[:, 'rating'] = 0\n",
        "    if negative_class.shape[0] < positive_class.shape[0]:\n",
        "      len_diff = positive_class.shape[0] - negative_class.shape[0]\n",
        "      movie_pool = [m for m in ratings['movieId'].unique() if m not in user_subset['movieId']]\n",
        "      unrated_movie_sample = random.sample(movie_pool, len_diff)\n",
        "      unrated_movies = pd.DataFrame()\n",
        "      unrated_movies.loc[:, 'movieId'] = unrated_movie_sample\n",
        "      unrated_movies.loc[:, 'userId'] = u\n",
        "      unrated_movies.loc[:, 'rating'] = 0\n",
        "    recoded_ratings = pd.concat([recoded_ratings, positive_class, negative_class, unrated_movies])\n",
        "  print_frequencies(recoded_ratings)\n",
        "  return recoded_ratings"
      ],
      "metadata": {
        "id": "5crd_-IGzTU3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_ratings(use_cache: bool = True) -> pd.DataFrame:\n",
        "  '''\n",
        "  Process the ratings dataset\n",
        "  '''\n",
        "  if use_cache and os.path.exists(RECODED_RATINGS_PATH):\n",
        "    ratings = load_dataset(RECODED_RATINGS_PATH, cols=['userId', 'movieId', 'rating'])\n",
        "  else:\n",
        "    ratings = load_dataset(path=RATINGS_PATH, cols=['userId', 'movieId', 'rating'])\n",
        "    print_frequencies(ratings)\n",
        "    ratings = subset_ratings(ratings)\n",
        "    ratings = binarise_dataset(ratings)\n",
        "    ratings.to_csv('ratings_recoded.csv')\n",
        "  return ratings"
      ],
      "metadata": {
        "id": "MleoucUFu_Ot"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_genres(metadata: pd.DataFrame) -> pd.DataFrame:\n",
        "  '''\n",
        "  Reformat genre data in columnar format\n",
        "  '''\n",
        "  genres = []\n",
        "  for line in metadata['genres']:\n",
        "    for genre in ast.literal_eval(line):\n",
        "      if genre['name'] not in genres:\n",
        "        genres.append(genre['name'])\n",
        "\n",
        "  genres = np.array(genres[:20]) # remove the erroneous genres\n",
        "  genre_matrix = np.zeros([metadata.shape[0], len(genres)], dtype=int)\n",
        "\n",
        "  for row_index, line in enumerate(tqdm(metadata['genres'])):\n",
        "    for genre in ast.literal_eval(line):\n",
        "      if genre['name'] in genres:\n",
        "        genre_index = np.where(genres==genre['name'])[0][0]\n",
        "        genre_matrix[row_index, genre_index] = 1\n",
        "\n",
        "  genre_matrix = pd.DataFrame(genre_matrix, columns=genres)\n",
        "  metadata = pd.concat([metadata, genre_matrix], axis=1)\n",
        "  metadata.drop('genres', axis=1, inplace=True)\n",
        "  return metadata"
      ],
      "metadata": {
        "id": "M82pOIcpxpdO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_in_metadata(ratings: pd.DataFrame) -> pd.DataFrame:\n",
        "  '''\n",
        "  Reformat genre data in columnar format\n",
        "  '''\n",
        "  metadata = load_dataset(path=METADATA_PATH, cols=['id', 'title', 'genres'])\n",
        "  metadata['id'] = pd.to_numeric(metadata['id'], errors='coerce')\n",
        "  metadata = parse_genres(metadata)\n",
        "  links = load_dataset(path=LINKS_PATH, cols=['movieId', 'tmdbId'])\n",
        "  links.rename(columns={'tmdbId':'id'}, inplace=True)\n",
        "  metadata = metadata.merge(links, how='inner', on='id')\n",
        "  ratings = ratings.merge(metadata.drop(columns=['id']), how='left', on='movieId').fillna(0)\n",
        "  return ratings"
      ],
      "metadata": {
        "id": "P_H6dJQn5a9R"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = process_ratings()\n",
        "ratings = merge_in_metadata(ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKp8E5Ihu_Lh",
        "outputId": "5d724bc5-290a-4ea8-c3c7-346114c1215f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ratings_recoded.csv dataset...\n",
            "Loading movies_metadata.csv dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45466/45466 [00:01<00:00, 23883.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading links.csv dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6x6yDhbU6BRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPfr4XNUcq175y260hSF8oM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}